from pydantic import BaseModel, Field
from typing import List, Dict, Optional, Any
import datetime


# ==========================================
# Phase 1: Input Data (Before LLM Processing)
# ==========================================

class CollectedData(BaseModel):
    """
    Data collected from raw sources (crawlers, API, RSS, etc.).
    Passed as context to the LLM.
    """
    UUID: str = Field(..., min_length=1)  # [MUST]: Unique identifier for the message/article.
    token: str = Field(..., min_length=1)  # [MUST]: Validation token for the endpoint/source.
    source: str | None = None  # (Optional): Origin platform (e.g., "Twitter", "BBC").
    target: str | None = None  # (Optional): Intended recipient or channel.
    prompt: str | None = None  # (Optional): Custom prompt override for this specific item.

    title: str | None = None  # [MUST]: Raw title of the article.
    authors: List[str] | None = []  # (Optional): List of authors found in metadata.
    content: str  # [MUST]: The main text body to be analyzed by LLM.
    pub_time: object | None = None  # (Optional): Original publish time (struct_time, datetime, str).
    informant: str | None = None  # (Optional): The specific source URL or informant ID.


# ==========================================
# Phase 2: Processed Output (LLM Result)
# ==========================================

class ProcessedData(BaseModel):
    """
    Structured intelligence data extracted and validated from LLM output.
    Design Philosophy: Fields are Optional to handle the "NonIntelligence" branching logic.
    """

    # --- System Fields (Inherited/Generated) ---
    UUID: str = Field(..., min_length=1)
    INFORMANT: str = Field(..., min_length=1)
    PUB_TIME: str | datetime.datetime | None = None  # Metadata time, distinct from event time.

    # --- Core Classification (Prompt: TAXONOMY, SUB_CATEGORY) ---
    TAXONOMY: str = Field(..., description="High-level category (e.g., 'Politics', 'NonIntelligence'). Dynamic string.")

    SUB_CATEGORY: List[str] | None = Field(
        default_factory=list,
        description="Specific tags selected from the prompt list (e.g., ['International Relations']). Dynamic list."
    )

    # --- Analysis Reasoning (Prompt: REASON) ---
    REASON: str | None = Field(
        None,
        description="Explanation for the classification (Used for both Valuable and Non-Intelligent items)."
    )

    # --- Event Details (Prompt: EVENT_TITLE, EVENT_BRIEF, EVENT_TEXT) ---
    EVENT_TITLE: str | None = Field(
        None,
        min_length=1,
        description="Core title of the intelligence event (<20 chars)."
    )

    EVENT_BRIEF: str | None = Field(
        None,
        min_length=1,
        description="Factual summary of the event (<50 chars)."
    )

    EVENT_TEXT: str | None = Field(
        None,
        description="Detailed intelligence report/briefing generated by LLM (>2000 chars if content allows)."
    )

    # --- Entities & Context (Prompt: TIME, LOCATION, GEOGRAPHY, PEOPLE, ORGANIZATION) ---
    TIME: List[str] | None = Field(
        default_factory=list,
        description="Standardized event dates extracted from text (Format: YYYY-MM-DD)."
    )

    LOCATION: List[str] | None = Field(
        default_factory=list,
        description="Specific locations mentioned (Cities, Regions)."
    )

    GEOGRAPHY: str | None = Field(
        None,
        description="Country ISO code (e.g., 'CN', 'US') or English name."
    )

    PEOPLE: List[str] | None = Field(
        default_factory=list,
        description="Key individuals involved."
    )

    ORGANIZATION: List[str] | None = Field(
        default_factory=list,
        description="Key organizations or groups involved."
    )

    # --- Impact Analysis (Prompt: IMPACT, RATE, TIPS) ---
    IMPACT: str | None = Field(
        None,
        description="Brief description of the event's impact (<50 chars)."
    )

    RATE: Dict[str, int] | None = Field(
        default_factory=dict,
        description="Scoring dictionary (1-10) for dimensions like Impact, Novelty, Actionability."
    )

    TIPS: str | None = Field(
        None,
        description="Analyst remarks or handling difficulties."
    )


# ==========================================
# Phase 3: Archival Storage (Database Schema)
# ==========================================

class ArchivedDataExtraFields(BaseModel):
    """
    Additional fields appended during the persistence layer (Database insertion).
    """
    RAW_DATA: Dict[str, Any] | None = Field(
        None,
        description="The full raw original message."
    )

    SUBMITTER: str | None = Field(
        None,
        description="Where the intelligence comes from."
    )

    APPENDIX: Dict[str, Any] | None = Field(
        None,
        description="Any extra metadata, file attachments, or extended properties."
    )


class ArchivedData(ProcessedData, ArchivedDataExtraFields):
    """
    Final model representing a record stored in the database.
    Combines processed intelligence with system archival metadata.
    """
    pass
